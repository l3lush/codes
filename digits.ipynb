{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digits.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu8UYWugHvkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dset\n",
        "from torch.utils.data import Dataset, SubsetRandomSampler\n",
        "\n",
        "from torchvision import transforms, models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFSOEXu9N4N-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DigitsDataset(Dataset):\n",
        "    def __init__ (self, folder_path, csv_file, transform=None):\n",
        "        self.path = os.path.join(folder_path, csv_file)\n",
        "        self.file = pd.read_csv(self.path)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #if torch.is_tensor(idx):\n",
        "            #idx = idx.tolist()\n",
        "        \n",
        "        if 'label' in self.file.columns:\n",
        "            y = self.file.iloc[idx, 0]\n",
        "            x = self.file.iloc[idx, 1:]\n",
        "            x = np.array([x])\n",
        "            x = x.astype('float32').reshape(28, 28)\n",
        "            if self.transform:\n",
        "                x = self.transform(x)\n",
        "            return x, y\n",
        "        \n",
        "        x = self.file.iloc[idx, :]\n",
        "        x = np.array([x])\n",
        "        x = x.astype('float32').reshape(28, 28)\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x\n",
        "\n",
        "def visualize_samples(dataset, indices, title=None, count=10):\n",
        "    plt.figure(figsize=(count*3,3))\n",
        "    indices_to_display = indices[:count]\n",
        "    if title:\n",
        "        plt.suptitle(\"%s %s/%s\" % (title, len(indices_to_display), len(indices)))\n",
        "    for i, index in enumerate(indices_to_display):\n",
        "        x, y = dataset[index]\n",
        "        plt.subplot(1, count, i+1)\n",
        "        plt.title(\"Label: %s\" % y.item())\n",
        "        plt.imshow(x.cpu().numpy().squeeze())\n",
        "        plt.grid(False)\n",
        "        plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ML6q7qrT0aG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "outputId": "fe45c64d-248e-499f-e8db-50a72885c24d"
      },
      "source": [
        "folder = '/content/drive/My Drive/digits'\n",
        "data_train = DigitsDataset(folder, 'train.csv', transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "indices = np.random.choice(np.arange(len(data_train)), 5, replace=False)\n",
        "visualize_samples(data_train, indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2160x216 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnDlSG3rJ40r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "data_size = len(data_train)\n",
        "validation_split = .2\n",
        "split = int(np.floor(validation_split * data_size))\n",
        "indices = list(range(data_size))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)\n",
        "val_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size,\n",
        "                                         sampler=val_sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-MPg6JMKh2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flattener(nn.Module):\n",
        "    def forward(self, x):\n",
        "        batch_size, *_ = x.shape\n",
        "        return x.view(batch_size, -1)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs, step_size=1, gam=0.99):    \n",
        "    loss_history = []\n",
        "    train_history = []\n",
        "    val_history = []\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gam)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        \n",
        "        loss_accum = 0\n",
        "        correct_samples = 0\n",
        "        total_samples = 0\n",
        "        for i_step, (x, y) in enumerate(train_loader):\n",
        "            x_gpu = x.to(device)\n",
        "            y_gpu = y.to(device)\n",
        "\n",
        "            prediction = model(x_gpu)\n",
        "            loss_value = loss(prediction, y_gpu)\n",
        "            optimizer.zero_grad()\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            _, indices = torch.max(prediction, 1)\n",
        "            correct_samples += torch.sum(indices == y_gpu)\n",
        "            total_samples += y.shape[0]\n",
        "            \n",
        "            loss_accum += loss_value\n",
        "\n",
        "\n",
        "        ave_loss = loss_accum / i_step\n",
        "        train_accuracy = float(correct_samples) / total_samples\n",
        "        val_accuracy = compute_accuracy(model, val_loader)\n",
        "        \n",
        "        loss_history.append(float(ave_loss))\n",
        "        train_history.append(train_accuracy)\n",
        "        val_history.append(val_accuracy)\n",
        "        scheduler.step()\n",
        "        print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % (ave_loss, train_accuracy, val_accuracy))\n",
        "        \n",
        "    return loss_history, train_history, val_history\n",
        "        \n",
        "def compute_accuracy(model, loader):\n",
        "    \"\"\"\n",
        "    Computes accuracy on the dataset wrapped in a loader\n",
        "    \n",
        "    Returns: accuracy as a float value between 0 and 1\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    correct_samples, total_samples = 0, 0\n",
        "    for i_step, (x, y) in enumerate(loader):\n",
        "            x_gpu = x.to(device)\n",
        "            y_gpu = y.to(device)\n",
        "\n",
        "            prediction = model(x_gpu) \n",
        "\n",
        "            _, indices = torch.max(prediction, 1)\n",
        "            correct_samples += torch.sum(indices == y_gpu)\n",
        "            total_samples += y.shape[0]\n",
        "    \n",
        "    return float(correct_samples) / total_samples\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUGK3trHLIj6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "bfbb2601-2f4c-4292-9605-8ba02beab32d"
      },
      "source": [
        "nn_model = nn.Sequential(\n",
        "            nn.Conv2d(1, 10, 3, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(10, 20, 3, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),    \n",
        "            Flattener(),\n",
        "            nn.Linear(360*2, 10),\n",
        "          )\n",
        "\n",
        "\n",
        "nn_model.type(torch.cuda.FloatTensor)\n",
        "nn_model.to(device)\n",
        "\n",
        "\n",
        "loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
        "optimizer = optim.Adam(nn_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "loss_history, train_history, val_history = train_model(nn_model, train_loader, val_loader, loss, optimizer, 10, 5, 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average loss: 0.275423, Train accuracy: 0.936012, Val accuracy: 0.966310\n",
            "Average loss: 0.093370, Train accuracy: 0.971190, Val accuracy: 0.974286\n",
            "Average loss: 0.074485, Train accuracy: 0.976845, Val accuracy: 0.972262\n",
            "Average loss: 0.063165, Train accuracy: 0.980744, Val accuracy: 0.967262\n",
            "Average loss: 0.052635, Train accuracy: 0.983810, Val accuracy: 0.977381\n",
            "Average loss: 0.019138, Train accuracy: 0.993452, Val accuracy: 0.981071\n",
            "Average loss: 0.010015, Train accuracy: 0.997143, Val accuracy: 0.983571\n",
            "Average loss: 0.006928, Train accuracy: 0.998185, Val accuracy: 0.982738\n",
            "Average loss: 0.005332, Train accuracy: 0.998810, Val accuracy: 0.983810\n",
            "Average loss: 0.004261, Train accuracy: 0.998958, Val accuracy: 0.981310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5YSUf6VLVY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fcd06157-c65b-4ace-ac8c-d4a5c19b651d"
      },
      "source": [
        "example = pd.read_csv('/content/drive/My Drive/digits/sample_submission.csv')\n",
        "example.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ImageId  Label\n",
              "0        1      0\n",
              "1        2      0\n",
              "2        3      0\n",
              "3        4      0\n",
              "4        5      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bhC0PwRT55Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = DigitsDataset(folder, 'test.csv', transform=transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1-jHxJiUK_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wN-yvQOUvDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, loader):\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    for i, x in enumerate(loader):\n",
        "        x_gpu = x.to(device)\n",
        "        pred = model(x_gpu)\n",
        "        pred = pred.argmax(axis=1).tolist()\n",
        "        predictions += pred\n",
        "    return np.array(predictions).flatten()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNuYsCewMH5O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "968269ba-93af-47a8-9432-c2bbc86487b4"
      },
      "source": [
        "nn_model = nn.Sequential(\n",
        "            nn.Conv2d(1, 10, 3, padding=2),\n",
        "            nn.BatchNorm2d(10),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(10, 20, 3, padding=0),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(20, 50, 3, padding=0),\n",
        "            nn.BatchNorm2d(50),\n",
        "            nn.ReLU(inplace=True),   \n",
        "            Flattener(),\n",
        "            nn.Linear(800, 100),\n",
        "            nn.BatchNorm1d(100),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(100, 10),\n",
        "          )\n",
        "\n",
        "nn_model.type(torch.cuda.FloatTensor)\n",
        "nn_model.to(device)\n",
        "\n",
        "loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
        "optimizer = optim.Adam(nn_model.parameters(), lr=1e-3, weight_decay=3e-4)\n",
        "\n",
        "loss_history, train_history, val_history = train_model(nn_model, train_loader, val_loader, loss, optimizer, 30, 5, 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-2f808545b3ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m           )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self, dst_type)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \"\"\"\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \"\"\"\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ3yRmf2MNZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "748ccf07-cd6c-4c8b-8455-122abbf75d2a"
      },
      "source": [
        "test_accuracy = compute_accuracy(nn_model, val_loader)\n",
        "print(\"Final test accuracy - \", test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final test accuracy -  0.9930952380952381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcEsE_7kcMaY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "57262ac4-31da-4b18-ae46-a63cee432983"
      },
      "source": [
        "preds = predict(nn_model, test_loader)\n",
        "name='pos.csv'\n",
        "pd.DataFrame(preds, index=np.arange(1, 28001), columns=['Label']).to_csv(name, index_label='ImageId')\n",
        "files.download(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_cfb3c4e8-ba84-4b75-981a-7ede3d706082\", \"pos.csv\", 212908)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA5JK8LQcsUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "old_preds = preds.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ru18L-r5SJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train = DigitsDataset(folder, 'train.csv', transform=transforms.Compose([transforms.ToPILImage(),\n",
        "                                                                              transforms.Resize((224, 224)),\n",
        "                                                                              transforms.ToTensor(),\n",
        "                                                                              # Use mean and std for pretrained models\n",
        "                                                                              # https://pytorch.org/docs/stable/torchvision/models.html\n",
        "                                                                              transforms.Normalize(mean=[0.485],\n",
        "                                                                              std=[0.229])]))\n",
        "\n",
        "data_test =  DigitsDataset(folder, 'test.csv', transform=transforms.Compose([transforms.ToPILImage(),\n",
        "                                                                              transforms.Resize((224, 224)),\n",
        "                                                                              transforms.ToTensor(),\n",
        "                                                                              # Use mean and std for pretrained models\n",
        "                                                                              # https://pytorch.org/docs/stable/torchvision/models.html\n",
        "                                                                              transforms.Normalize(mean=[0.485],\n",
        "                                                                              std=[0.229])]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPESKwjM6ik4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "data_size = len(data_train)\n",
        "validation_split = .2\n",
        "split = int(np.floor(validation_split * data_size))\n",
        "indices = list(range(data_size))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)\n",
        "val_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size,\n",
        "                                         sampler=val_sampler)\n",
        "test_loader = torch.utils.data.DataLoader(data_test, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdFrLLjv6kpw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "d633b39d-103d-412f-da8d-e61c45337047"
      },
      "source": [
        "model_resnet = models.resnet18(pretrained=False)\n",
        "\n",
        "num_ftrs = model_resnet.fc.in_features\n",
        "model_resnet.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_resnet = model_resnet.to(device)\n",
        "\n",
        "loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
        "optimizer = optim.Adam(model_resnet.parameters(), lr=1e-3, weight_decay=3e-4)\n",
        "\n",
        "loss_history, train_history, val_history = train_model(model_resnet, train_loader, val_loader, loss, optimizer, 10, 5, 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3f3126ec8359>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_resnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_resnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_resnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccDe6iT27927",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9406f9e-2c82-4834-b74f-548d6e7c7240"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNui2Q0D-zsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e68b9787-8db6-423b-d4d7-6781a9700a01"
      },
      "source": [
        "model_resnet.conv1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ovP2XbvACob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}